{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment #1: Applying kfold Cross-Validation on the mnist Dataset"
      ],
      "metadata": {
        "id": "Idmc84Wae17W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "mnist=fetch_openml('mnist_784',as_frame=False)\n",
        "X,y=mnist.data,mnist.target\n",
        "\n",
        "y_5 = y =='5'\n",
        "\n",
        "X_train,X_test,y_train,y_test = X[:60000],X[60000:], y_5[:60000],y_5[60000:]\n",
        "X_trainset,X_valid,y_trainset,y_valid = X_train[:-10000],X_train[-10000:], y_train[:-10000],y_train[-10000:]\n",
        "\n",
        "# Normalization (0 ~ 1) -> To avoid overflow\n",
        "X_trainset_scaled = X_trainset / 255.0\n",
        "X_valid_scaled = X_valid / 255.0\n",
        "X_test_scaled = X_test / 255.0\n",
        "\n",
        "model1 = Sequential()\n",
        "input_shape = X_trainset_scaled.shape[1:]\n",
        "\n",
        "model1.add(Dense(128,input_shape=input_shape,activation='relu'))\n",
        "model1.add(Dense(128,activation='relu'))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()\n",
        "history1=model1.fit(X_trainset_scaled, y_trainset, epochs=10, batch_size=32, validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "predictions1=model1.predict(X_test_scaled)\n",
        "y_hat=(predictions1>0.5).astype(int)\n",
        "\n",
        "print(classification_report(y_test, y_hat))"
      ],
      "metadata": {
        "id": "kXmEXrL10SAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "1387fbbf-10f7-48ed-b3e7-7f685ef752dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m100,480\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m16,512\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m117,121\u001b[0m (457.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,121</span> (457.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,121\u001b[0m (457.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,121</span> (457.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0884 - val_accuracy: 0.9887 - val_loss: 0.0369\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0191 - val_accuracy: 0.9914 - val_loss: 0.0302\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.9914 - val_loss: 0.0316\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0093 - val_accuracy: 0.9916 - val_loss: 0.0379\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 0.9932 - val_loss: 0.0286\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9930 - val_loss: 0.0377\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9946 - val_loss: 0.0314\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9933 - val_loss: 0.0311\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9937 - val_loss: 0.0306\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9918 - val_loss: 0.0384\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9108\n",
            "        True       0.96      0.98      0.97       892\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.99      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "X_trainset_scaled = X_train / 255.0\n",
        "\n",
        "# Set up K-Fold\n",
        "k = 6\n",
        "seed=1404\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
        "\n",
        "fold = 1\n",
        "reports = []\n",
        "\n",
        "for train_index, val_index in skf.split(X_trainset_scaled, y_train):\n",
        "    print(f\"ğŸŒ€ Fold {fold}\")\n",
        "\n",
        "    X_train_fold, X_val_fold = X_trainset_scaled[train_index], X_trainset_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=input_shape),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              epochs=10,\n",
        "              batch_size=32,\n",
        "              verbose=0,\n",
        "              validation_data=(X_val_fold, y_val_fold))\n",
        "\n",
        "    val_preds = (model.predict(X_val_fold) > 0.5).astype(int)\n",
        "    report = classification_report(y_val_fold, val_preds, output_dict=True)\n",
        "    reports.append(report)\n",
        "\n",
        "    print(fold, classification_report(y_val_fold, val_preds))\n",
        "    fold += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1jetzZjWNYF",
        "outputId": "6fb4b1b0-1b21-4b24-ac37-b347b109654b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ€ Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "1               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9096\n",
            "        True       0.97      0.96      0.96       904\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "ğŸŒ€ Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "2               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9096\n",
            "        True       0.98      0.97      0.97       904\n",
            "\n",
            "    accuracy                           1.00     10000\n",
            "   macro avg       0.99      0.98      0.99     10000\n",
            "weighted avg       1.00      1.00      1.00     10000\n",
            "\n",
            "ğŸŒ€ Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "3               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9096\n",
            "        True       0.97      0.96      0.97       904\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "ğŸŒ€ Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "4               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      1.00      9097\n",
            "        True       0.98      0.95      0.96       903\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.97      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "ğŸŒ€ Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "5               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9097\n",
            "        True       0.98      0.95      0.97       903\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "ğŸŒ€ Fold 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "6               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9097\n",
            "        True       0.99      0.95      0.97       903\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculation of average f1-score for class 'true'"
      ],
      "metadata": {
        "id": "Ogz-3jFApr_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "\n",
        "for r in reports:\n",
        "    f1_scores.append(r.get('True', {}).get('f1-score', 0.0))\n",
        "\n",
        "print(f\"Average F1-score (positive class - '5'): {np.mean(f1_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHnXM5X1rfVf",
        "outputId": "e260fe98-d01b-4c4b-98bd-b4b9607bad93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average F1-score (positive class - '5'): 0.9679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment # 2: Optimization of the Neural Network for Cat vs Noncat Problem"
      ],
      "metadata": {
        "id": "_SEYYogVfbKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from utils import dataset_loader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "X_train,y_train,X_test,y_test = dataset_loader('./')\n",
        "\n",
        "# reshape -> flat\n",
        "X_train_flat=X_train.reshape(X_train.shape[0],-1)\n",
        "X_train_flat.shape\n",
        "X_test_flat=X_test.reshape(X_test.shape[0],-1)\n",
        "X_test_flat.shape\n",
        "\n",
        "# normalize\n",
        "X_train_scaled=X_train_flat / 255.0\n",
        "X_test_scaled=X_test_flat / 255.0\n",
        "\n",
        "input_shape=X_train_scaled.shape[1:]\n",
        "\n",
        "# fit model (2 Hidden Layers)\n",
        "model=Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "#tf.keras.utils.plot_model(model,'test.png',show_shapes=True)\n",
        "#plot_model(model,'test.png',show_shapes=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "history=model.fit(X_train_scaled,y_train,epochs=10,batch_size=32)\n",
        "predictions=model.predict(X_test_scaled)\n",
        "\n",
        "y_hat=(predictions>0.5).astype(int)\n",
        "print(classification_report(y_test,y_hat))"
      ],
      "metadata": {
        "id": "nX_QY2WqtMd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be2e75b-d4a4-4066-d284-5c2bbde907f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - binary_accuracy: 0.5236 - loss: 2.1041\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - binary_accuracy: 0.5105 - loss: 0.9370\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.6698 - loss: 0.6213\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.6720 - loss: 0.5983\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.6529 - loss: 0.6371\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.6954 - loss: 0.5740\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.6585 - loss: 0.5899\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.7593 - loss: 0.5209\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.8092 - loss: 0.5084\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.8012 - loss: 0.4806\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.65      0.58        17\n",
            "           1       0.79      0.70      0.74        33\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.66      0.67      0.66        50\n",
            "weighted avg       0.70      0.68      0.69        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trying Different Optimizers"
      ],
      "metadata": {
        "id": "HOpXajtfzKMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set seeds\n",
        "seed=1404\n",
        "os.environ['PYTHONHASHSEED'] = '1404'\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "optimizers = [\n",
        "    tf.keras.optimizers.SGD(),\n",
        "    tf.keras.optimizers.RMSprop(),\n",
        "    tf.keras.optimizers.Adam(),\n",
        "    tf.keras.optimizers.AdamW(),\n",
        "    tf.keras.optimizers.Nadam()\n",
        "]\n",
        "\n",
        "for opt in optimizers:\n",
        "    print(f\"\\nTesting optimizer: {opt._name if hasattr(opt, '_name') else opt.__class__.__name__}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    predictions = model.predict(X_test_scaled)\n",
        "    y_hat = (predictions > 0.5).astype(int)\n",
        "\n",
        "    f1 = f1_score(y_test, y_hat)\n",
        "    print(f\"F1-Score with {opt.__class__.__name__}: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hRojaAIzHP5",
        "outputId": "26422f30-5323-4bfb-eab3-d09ecfa9936c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing optimizer: SGD\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "F1-Score with SGD: 0.7742\n",
            "\n",
            "Testing optimizer: RMSprop\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "F1-Score with RMSprop: 0.5283\n",
            "\n",
            "Testing optimizer: Adam\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "F1-Score with Adam: 0.8824\n",
            "\n",
            "Testing optimizer: AdamW\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "F1-Score with AdamW: 0.1622\n",
            "\n",
            "Testing optimizer: Nadam\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "F1-Score with Nadam: 0.5769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment # 3: Selecting Activation Function for the Neural Network for Cat vs Noncat Problem: Adam Optimzer with k=5 cross-validation"
      ],
      "metadata": {
        "id": "_CNbPIiX00XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "#from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "# For reproducibility\n",
        "import os, random\n",
        "seed=1404\n",
        "os.environ['PYTHONHASHSEED'] = '1404'\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "input_shape = X_train_scaled.shape[1:]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "activations = ['relu', 'sigmoid', 'tanh']\n",
        "\n",
        "for activation in activations:\n",
        "    print(f\"\\n Evaluating activation function: {activation}\")\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
        "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "        model = Sequential([\n",
        "            Input(shape=input_shape),\n",
        "            Dense(64, activation=activation),\n",
        "            Dense(64, activation=activation),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "        )\n",
        "\n",
        "        model.fit(X_tr, y_tr, epochs=10, batch_size=32, verbose=0)\n",
        "        y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
        "        f1 = f1_score(y_val, y_pred)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "    std_f1 = np.std(f1_scores)\n",
        "    print(f\"{activation} â€” Mean F1-score: {mean_f1:.4f} Â± {std_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGMF3RGt2PxT",
        "outputId": "575d0c71-8cce-4ade-ba1e-df94ef3011b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluating activation function: relu\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "relu â€” Mean F1-score: 0.2862 Â± 0.0893\n",
            "\n",
            " Evaluating activation function: sigmoid\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "sigmoid â€” Mean F1-score: 0.0000 Â± 0.0000\n",
            "\n",
            " Evaluating activation function: tanh\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "tanh â€” Mean F1-score: 0.0000 Â± 0.0000\n"
          ]
        }
      ]
    }
  ]
}